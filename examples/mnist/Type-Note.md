# 型について

## `torch.Tensor`

`torch.Tensor` は、PyTorchにおける基本的なデータ構造で、数値の配列  
NumPyの `numpy.ndarray` と非常によく似ているが、PyTorchのテンソルはGPU上で計算を行うことができ、逆伝播（バックプロパゲーション）をサポートしている

`torch.Tensor` の特性：

- **多次元配列**：
  - `torch.Tensor` はスカラー、ベクトル、行列、さらには高次元のテンソルを表すことができる
  
- **自動微分**：
  - PyTorchのテンソルは、自動微分機能をサポートしており、逆伝播を通じて勾配を計算することができる
  
- **GPUサポート**：
  - `torch.Tensor` はGPU上で計算を行うことができ、大規模な計算を高速に行うことができる

例：

```python
import torch

# 2x3のテンソルを作成
x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)
print(x)

# テンソルをGPUに移動
if torch.cuda.is_available():
    x = x.to('cuda')
    print(x)
```

これにより、PyTorchのテンソルを使用して効率的に計算を行うことができる

## `torch.nn.Conv2d()`

PyTorchで2次元畳み込み層を定義するためのクラス  

### 引数の解説

#### 1. 第一引数 (`in_channels`)

- **説明**: 入力チャネルの数を指定。グレースケール画像の場合は1、RGB画像の場合は3。それ以上もある。
- **例**: `1` はグレースケール画像を、`3` はRGB画像を示す。

#### 2. 第二引数 (`out_channels`)

- **説明**: 出力チャネルの数を指定。畳み込み操作の後に得られるフィルタ（特徴マップ）の数。
- **例**: `32` は、32個の異なるフィルタを使用して特徴マップを生成することを示す。

#### 3. 第三引数 (`kernel_size`)

- **説明**: 畳み込みカーネル（フィルタ）のサイズを指定。整数を指定すると、正方形のカーネルサイズになります。また、タプルを指定することで縦横のサイズを個別に指定できる。
- **例**: `3` は `3x3` のカーネルを使用することを示す。

#### 4. 第四引数 (`stride`)

- **説明**: 畳み込みカーネルが画像上を移動するステップのサイズを指定。整数を指定すると、縦横同じステップサイズ。また、タプルを指定することで縦横のステップサイズを個別に指定できる。
- **例**: `1` はカーネルが1ピクセルずつ移動することを示す。

### 返り値

畳み込み層 (`nn.Conv2d`) を適用した結果は、入力テンソルの特徴マップが生成される。この特徴マップは、畳み込みカーネルによって抽出された特徴を含んでいる。

具体的には、以下のような形のテンソルが返される：

$$
 \text{Output}(i, j, k) = \sum_{c=1}^{C} \sum_{m=1}^{M} \sum_{n=1}^{N} \text{Input}(i+m, j+n, c) \cdot \text{Kernel}(m, n, c, k) + \text{Bias}(k)
$$

ここで、

- $\text{Output}(i, j, k)$ は出力特徴マップの$k$番目のチャネルの$(i, j)$の位置の値。
- $\text{Input}(i+m, j+n, c)$は入力データの$c$番目のチャネル（=出力特徴マップ）の$(i+m, j+n)$の位置の値。
- $\text{Kernel}(m, n, c, k)$は$k$番目の出力チャネルに対応するフィルタの$c$番目の入力チャネルに対する$(m, n)$の位置の値。
- $\text{Bias}(k)$は$k$番目の出力チャネルに対するバイアス項。

この計算は**線形演算**であり、**入力とカーネルの加重和**を返す

 `kernel` や `input` の値は、入力データやフィルタの具体的な数値を示す

#### 入力データ（Input）の値

入力データは、一般的に画像データであり、ピクセルの強度値を示す  
この値は、画像の種類によって異なる

- **グレースケール画像**:
  - 各ピクセルは1つの強度値を持つ
  - 値の範囲は通常0から255の整数値
    - ニューラルネットワークに入力する前に正規化されて0から1の間の浮動小数点数に変換されることが多いで
- **RGB画像**:
  - 各ピクセルは3つの値（赤、緑、青の強度値）を持つ
  - これらも通常0から255の範囲の整数値であり、正規化されて0から1の範囲の浮動小数点数に変換される

#### カーネル（Kernel）の値

カーネルの値は、畳み込み操作を行うフィルタの重みを示す  
カーネルは小さな行列であり、畳み込み層の学習プロセス中に更新されるパラメータ  
各カーネルの要素は、フィルタが画像の局所領域から特徴を抽出するために使用する重み（伊藤先生の授業でやったようなもの。）

### 具体例

### グレースケール画像の場合

例えば、次のような3x3のグレースケール画像と3x3のカーネルを考えます：

$$
\text{Input} =
\begin{bmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{bmatrix}
$$

$$
\text{Kernel} =
\begin{bmatrix}
-1 & 0 & 1 \\
-1 & 0 & 1 \\
-1 & 0 & 1
\end{bmatrix}
$$

ここで、入力の各値はピクセルの強度値（正規化された場合は0から1の範囲の浮動小数点数）、カーネルの各値はフィルタの重みを示す

### 畳み込み操作の詳細

畳み込み操作の際に、カーネルを画像上でスライドさせ、カーネルと入力の対応する位置の要素ごとの積の和を計算する。

### 計算例

$$
\text{Output}(1, 1) =
(1 \cdot -1) + (2 \cdot 0) + (3 \cdot 1) + (4 \cdot -1) + (5 \cdot 0) + (6 \cdot 1) + (7 \cdot -1) + (8 \cdot 0) + (9 \cdot 1)
= -1 + 0 + 3 - 4 + 0 + 6 - 7 + 0 + 9 = 6
$$

この計算を入力全体に対して行う

### RGB画像の場合

RGB画像の場合、入力の各ピクセルは3つの値（赤、緑、青の強度値）を持つ。  
畳み込み操作では、3つのチャネルそれぞれに対してフィルタを適用し、結果を合計する

例えば、次のような3x3のRGB画像のピクセル：

$$
\text{Input} =
\begin{bmatrix}
(1, 2, 3) & (4, 5, 6) & (7, 8, 9) \\
(10, 11, 12) & (13, 14, 15) & (16, 17, 18) \\
(19, 20, 21) & (22, 23, 24) & (25, 26, 27)
\end{bmatrix}
$$

カーネルも3つのチャネルそれぞれに対して別々に定義される（正方行列とは限らない）：

$$
\text{Kernel} =
\begin{bmatrix}
(-1, -1, -1) & (0, 0, 0) & (1, 1, 1)
\end{bmatrix}
$$

この場合、各チャネルに対して独立に畳み込みを行い、最終的に結果を合計する

### PyTorchでの例

次に、PyTorchを使った具体例を示します：

出力テンソルのサイズは、以下：

$$
\text{output height} = \frac{(\text{input height} - \text{kernel height} + 2 \times \text{padding})}{\text{stride}} + 1
$$

$$
 \text{output width} = \frac{(\text{input width} - \text{kernel width} + 2 \times \text{padding})}{\text{stride}} + 1 
$$

ここで、`padding` はゼロパディングのピクセル数  
ゼロパディングは、`padding` 引数で指定するが、この例では省略されている

### 具体例

#### `conv1` と `conv2` の連携

```python
import torch
import torch.nn as nn

# 入力の定義 (バッチサイズ, チャネル数, 高さ, 幅)
input = torch.randn(1, 1, 28, 28)  # 例として、バッチサイズ1、グレースケール（チャネル1）、28x28の画像

# 畳み込み層の定義
conv1 = nn.Conv2d(1, 32, 3, 1)  # 第一層: グレースケール画像（チャネル1）を32チャネルに
conv2 = nn.Conv2d(32, 64, 3, 1)  # 第二層: 第一層の出力（32チャネル）を64チャネルに

# 畳み込み層の適用
output1 = conv1(input)
output2 = conv2(output1)

# 出力のサイズ確認
print(output1.shape)  # torch.Size([1, 32, 26, 26])
print(output2.shape)  # torch.Size([1, 64, 24, 24])
```

#### 各ステップの詳細な説明

1. **入力テンソル**：
   - 入力テンソル `input` は、サイズが `[1, 1, 28, 28]` の4次元テンソルで、これはバッチサイズが1、チャネル数が1（グレースケール画像）、高さ28、幅28の画像

2. **第一畳み込み層 (`conv1`)**：
   - 第一引数 `1`：入力チャネル数。グレースケール画像なので1。
   - 第二引数 `32`：出力チャネル数。32個のフィルタを適用して32チャネルの出力を得る。
   - 第三引数 `3`：カーネルサイズ。`3x3` のカーネルを使用。
   - 第四引数 `1`：ストライド。カーネルが1ピクセルずつ移動。
   - 出力テンソル `output1` はサイズ `[1, 32, 26, 26]` になります。

3. **第二畳み込み層 (`conv2`)**：
   - 第一引数 `32`：入力チャネル数。`conv1` の出力チャネル数と一致。
   - 第二引数 `64`：出力チャネル数。64個のフィルタを適用して64チャネルの出力を得る。
   - 第三引数 `3`：カーネルサイズ。`3x3` のカーネルを使用。
   - 第四引数 `1`：ストライド。カーネルが1ピクセルずつ移動。
   - 出力テンソル `output2` はサイズ `[1, 64, 24, 24]` になる。

#### 返り値の説明

`nn.Conv2d` の返り値は、入力テンソルに対して畳み込み操作を適用した後の出力テンソルです。この出力テンソルは、次の層に入力として渡されます。出力テンソルのサイズは以下の式で計算されます：

$$
 \text{output height} = \frac{(\text{input height} - \text{kernel height} + 2 \times \text{padding})}{\text{stride}} + 1
$$

$$
 \text{output width} = \frac{(\text{input width} - \text{kernel width} + 2 \times \text{padding})}{\text{stride}} + 1
$$

この計算により、`conv1` の出力サイズは `[1, 32, 26, 26]`、`conv2` の出力サイズは `[1, 64, 24, 24]` になる

##### 4次元テンソルとは

深層学習において一般的に使用されるデータ構造で、特に畳み込みニューラルネットワーク（CNN）で入力データや中間層のデータを表現するために用いられる  
各次元は以下を表す。

1. **バッチサイズ（Batch Size）**：
   - データのバッチ（小分けされたデータセット）の数を示す
     - モデルのトレーニングや推論の際に、複数のデータを一度に処理するために使用される
   - 例：バッチサイズが32の場合、1バッチに32個のサンプルが含まれる

2. **チャネル数（Number of Channels）**：
   - 各データサンプルのチャネル数を示します。
     - 例えば、グレースケール画像の場合は1チャネル、RGB画像の場合は3チャネル
   - 畳み込み層の中間層では、フィルタ数に対応してチャネル数が増加
   - 例：RGB画像は3チャネル、特徴マップが32個の畳み込み層の出力は32チャネル

3. **高さ（Height）**：
   - 画像や特徴マップの縦方向のピクセル数
   - 例：28ピクセルの高さを持つ画像

4. **幅（Width）**：
   - 画像や特徴マップの横方向のピクセル数
   - 例：28ピクセルの幅を持つ画像

### まとめ

- **第一引数 (`in_channels`)**: 入力チャネルの数。
- **第二引数 (`out_channels`)**: 出力チャネルの数。
- **第三引数 (`kernel_size`)**: 畳み込みカーネルのサイズ。
- **第四引数 (`stride`)**: 畳み込みカーネルの移動ステップサイズ。

この畳み込み層を使用することで、入力データから特徴を抽出し、ニューラルネットワークの後続層に渡すことができます。